# Anomalies detection in limit order books data

This repository contains the source code and resources for the master's thesis **"Anomalies Detection in Limit Order Books Data"**, which focuses on detecting suspicious or manipulative trading behaviors (especially **spoofing**) in historical financial market data using unsupervised machine learning.

## ğŸ“Œ Abstract

Modern financial markets are fast-paced, complex, and increasingly targeted by sophisticated forms of manipulation.
This thesis focuses on anomaly detection in time series derived from limit order books, aiming to identify manipulative behavior known as **spoofing**.
Due to the absence of annotated data, unsupervised machine learning methods are applied to real historical data.
Six methods are implemented:

- Isolation Forest
- Local Outlier Factor
- One-Class SVM
- Fully Connected Autoencoder
- Convolutional Autoencoder
- Transformer-based Autoencoder

The models are evaluated using the less commonly known metrics **Excess Mass** and **Mass Volume**, with the Isolation Forest and Transformer models achieving the best results.
By combining the most effective models, a robust tool is created, capable of detecting suspicious behavior without manual annotation.
The proposed solution efficiently identifies high-risk areas for subsequent expert analysis and thus offers a practical contribution to detecting illicit practices in financial markets.

## ğŸ› ï¸ Technologies Used

- **Python 3.11**
- [NumPy](https://pypi.org/project/numpy/)
- [Pandas](https://pypi.org/project/pandas/)
- [Matplotlib](https://pypi.org/project/matplotlib/)
- [Scikit-learn](https://pypi.org/project/scikit-learn/)
- [PyTorch](https://pypi.org/project/torch/)
- [Weights & Biases (WandB)](https://pypi.org/project/wandb/)
- [Plotly](https://pypi.org/project/plotly/)
- [Dash](https://dash.plotly.com/)

## ğŸš€ Getting Started

1. **Clone the repository** to your local machine using the following command:

```bash
git clone --recursive https://github.com/SpeekeR99/DP_2024_2025_Zappe.git
cd DP_2024_2025_Zappe
```

2. **Create a virtual environment** and **install dependencies**

```bash
python -m venv venv
source venv/bin/activate  # On Windows use `call venv\Scripts\activate.bat`
pip install -r requirements.txt
```

3. **Run** the pipeline

The full pipeline includes:

- Downloading the raw message style data from the exchange server
- Preprocessing the data
  - Reconstructing the order book
  - Feature extraction
- Model training and evaluation
- Visualization of the results

Steps:

- Run the `src/A7/download_eobi.py` script to download the raw messages
- Use the `src/data_preprocess/json-detailed2lobster.py` and `src/data_preprocess/augment_lobster.py` scripts to transform and enrich the data
- Train models using:
  - `src/anomaly_detection/models/autoencoder.py` for the autoencoder models
  - `src/anomaly_detection/models/if_ocsvm_lof.py` for the scikit-learn models
- Evaluation happens automatically during the training process 
- Finally, run `src/anomaly_detection/models/ensemble.py` for the final ensemble model and visualization of the detection results and evaluation metrics
- Optionally, use `src/visualization/visuals.py` to visualize the results in an interactive web application

## ğŸ“ Repository Structure

```plaintext
data/                     # Original and preprocessed LOB datasets (.json, .csv)
doc/                      # Thesis document (.pdf)
img/                      # All figures, visualizations, evaluation results
lib/
  â”œâ”€â”€ diffi/              # Feature importance algorithm
  â””â”€â”€ eval/               # EM/MV metric implementations
models/                   # Trained models (empty by default)
src/
  â”œâ”€â”€ A7/                 # EOBI and Orderbook data downloaders
  â”œâ”€â”€ data_preprocess/    # Data conversion and feature engineering
  â”œâ”€â”€ meta_centrum/       # Scripts for remote training (MetaCentrum)
  â””â”€â”€ anomaly_detection/
       â”œâ”€â”€ models/        # All ML model training scripts
       â”œâ”€â”€ eval/          # Metric definitions and evaluation routines
       â”œâ”€â”€ data/          # Data loaders and utilities
       â””â”€â”€ analysis/      # Feature selection and visualization tools
  â””â”€â”€ visualization/      # Interactive dashboard
res/                      # Output anomaly detection results
requirements.txt          # Python dependencies
```

---

# Detekce anomÃ¡liÃ­ v datech z knih limitnÃ­ch objednÃ¡vek

Tento repozitÃ¡Å™ obsahuje zdrojovÃ½ kÃ³d a souvisejÃ­cÃ­ materiÃ¡ly k diplomovÃ© prÃ¡ci **â€Detekce anomÃ¡liÃ­ v datech z knih limitnÃ­ch objednÃ¡vekâ€œ**, kterÃ¡ se zamÄ›Å™uje na detekci podezÅ™elÃ©ho nebo manipulativnÃ­ho chovÃ¡nÃ­ (zejmÃ©na **spoofingu**) v historickÃ½ch datech z finanÄnÃ­ch trhÅ¯ pomocÃ­ metod uÄenÃ­ bez uÄitele.

## ğŸ“Œ Abstrakt

ModernÃ­ finanÄnÃ­ trhy jsou rychlÃ©, komplexnÃ­ a stÃ¡le ÄastÄ›ji se stÃ¡vajÃ­ cÃ­lem sofistikovanÃ½ch forem manipulace.
Tato prÃ¡ce se zamÄ›Å™uje na detekci anomÃ¡liÃ­ v ÄasovÃ½ch Å™adÃ¡ch odvozenÃ½ch z knih limitnÃ­ch objednÃ¡vek s cÃ­lem rozpoznat manipulativnÃ­ chovÃ¡nÃ­ zvanÃ© **spoofing**.
Vzhledem k absenci anotovanÃ½ch dat jsou pouÅ¾ity metody strojovÃ©ho uÄenÃ­ bez uÄitele aplikovanÃ© na reÃ¡lnÃ¡ historickÃ¡ data.
V prÃ¡ci je implementovÃ¡no Å¡est metod:

- izolaÄnÃ­ les
- lokÃ¡lnÃ­ faktor odlehlosti
- jednotÅ™Ã­dnÃ­ SVM
- plnÄ› propojenÃ½ autoenkodÃ©r
- konvoluÄnÃ­ autoenkodÃ©r
- transformer autoenkodÃ©r

Modely jsou evaluovÃ¡ny pomocÃ­ mÃ©nÄ› znÃ¡mÃ½ch metrik **Excess Mass** a **Mass Volume**, pÅ™iÄemÅ¾ nejlÃ©pe si vedou modely izolaÄnÃ­ les a transformer.
KombinacÃ­ nejvÃ½konnÄ›jÅ¡Ã­ch modelÅ¯ vznikl robustnÃ­ nÃ¡stroj schopnÃ½ odhalit podezÅ™elÃ© chovÃ¡nÃ­ bez ruÄnÃ­ anotace.
NavrÅ¾enÃ© Å™eÅ¡enÃ­ efektivnÄ› identifikuje rizikovÃ© oblasti pro nÃ¡slednou expertnÃ­ analÃ½zu a pÅ™edstavuje tak praktickÃ½ pÅ™Ã­nos pro detekci nelegÃ¡lnÃ­ch praktik na finanÄnÃ­ch trzÃ­ch.

## ğŸ› ï¸ PouÅ¾itÃ© technologie

- **Python 3.11**
- [NumPy](https://pypi.org/project/numpy/)
- [Pandas](https://pypi.org/project/pandas/)
- [Matplotlib](https://pypi.org/project/matplotlib/)
- [Scikit-learn](https://pypi.org/project/scikit-learn/)
- [PyTorch](https://pypi.org/project/torch/)
- [Weights & Biases (WandB)](https://pypi.org/project/wandb/)
- [Plotly](https://pypi.org/project/plotly/)
- [Dash](https://dash.plotly.com/)

## ğŸš€ Jak zaÄÃ­t

1. **Naklonujte repozitÃ¡Å™** do lokÃ¡lnÃ­ho stroje pomocÃ­ pÅ™Ã­kazu:

```bash
git clone --recursive https://github.com/SpeekeR99/DP_2024_2025_Zappe.git
cd DP_2024_2025_Zappe
```

2. **VytvoÅ™te virtuÃ¡lnÃ­ prostÅ™edÃ­** a **nainstalujte zÃ¡vislosti**

```bash
python -m venv venv
source venv/bin/activate  # Na Windows pouÅ¾ijte `call venv\Scripts\activate.bat`
pip install -r requirements.txt
```

3. **SpusÅ¥te** pipeline

CelÃ¡ pipeline zahrnuje:

- StahovÃ¡nÃ­ surovÃ½ch dat ve stylu zprÃ¡v z burzovnÃ­ho serveru
- PÅ™edzpracovÃ¡nÃ­ dat
  - Rekonstrukce knihy objednÃ¡vek
  - Extrakce pÅ™Ã­znakÅ¯
- TrÃ©nink a vyhodnocenÃ­ modelu
- Vizualizace vÃ½sledkÅ¯

Kroky:

- SpusÅ¥te skript `src/A7/download_eobi.py` pro staÅ¾enÃ­ surovÃ½ch zprÃ¡v
- PouÅ¾ijte skripty `src/data_preprocess/json-detailed2lobster.py` a `src/data_preprocess/augment_lobster.py` pro transformaci a obohacenÃ­ dat
- NatrÃ©nujte modely pomocÃ­:
  - `src/anomaly_detection/models/autoencoder.py` pro autoenkodÃ©r modely
  - `src/anomaly_detection/models/if_ocsvm_lof.py` pro scikit-learn modely
- VyhodnocenÃ­ probÃ­hÃ¡ automaticky bÄ›hem trÃ©ninkovÃ©ho procesu
- Nakonec spusÅ¥te `src/anomaly_detection/models/ensemble.py` pro finÃ¡lnÃ­ soubor modelÅ¯ a vizualizaci vÃ½sledkÅ¯ detekce a hodnotÃ­cÃ­ch metrik
- VolitelnÄ› pouÅ¾ijte `src/visualization/visuals.py` pro vizualizaci vÃ½sledkÅ¯ v interaktivnÃ­ webovÃ© aplikaci

## ğŸ“ Struktura repozitÃ¡Å™e

```plaintext
data/                     # PÅ¯vodnÃ­ a pÅ™edzpracovanÃ¡ LOB data (.json, .csv)
doc/                      # Dokument diplomovÃ© prÃ¡ce (.pdf)
img/                      # VÅ¡echny obrÃ¡zky, vizualizace, hodnotÃ­cÃ­ vÃ½sledky
lib/
  â”œâ”€â”€ diffi/              # Algoritmus pro dÅ¯leÅ¾itost pÅ™Ã­znakÅ¯
  â””â”€â”€ eval/               # Implementace EM/MV metrik
models/                   # NatrÃ©novanÃ© modely (ve vÃ½chozÃ­m nastavenÃ­ prÃ¡zdnÃ©)
src/
  â”œâ”€â”€ A7/                 # EOBI a downloader knih objednÃ¡vek
  â”œâ”€â”€ data_preprocess/    # Konverze dat a inÅ¾enÃ½rstvÃ­ pÅ™Ã­znakÅ¯
  â”œâ”€â”€ meta_centrum/       # Skripty pro vzdÃ¡lenÃ½ trÃ©nink (MetaCentrum)
  â””â”€â”€ anomaly_detection/
	   â”œâ”€â”€ models/        # VÅ¡echny skripty pro trÃ©nink ML modelÅ¯
	   â”œâ”€â”€ eval/          # Definice metrik a vyhodnocovacÃ­ rutiny
	   â”œâ”€â”€ data/          # NaÄÃ­tÃ¡nÃ­ dat a utility
	   â””â”€â”€ analysis/      # NÃ¡stroje pro vÃ½bÄ›r pÅ™Ã­znakÅ¯ a vizualizaci
  â””â”€â”€ visualization/      # InteraktivnÃ­ dashboard
res/                      # VÃ½stupnÃ­ vÃ½sledky detekce anomÃ¡liÃ­
requirements.txt          # ZÃ¡vislosti Pythonu
```
